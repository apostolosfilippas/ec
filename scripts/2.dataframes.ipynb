{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
        "\n",
        "### ðŸ“˜ **Class**: E-Commerce\n",
        "\n",
        "### ðŸ“‹ **Topic**: DataFrames and Analyzing Data with Python\n",
        "\n",
        "ðŸš« **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 1\n",
        "\n",
        "**Topic**: We will learn the most useful data structure in Python: the DataFrame. We will also see how easy it is to read and write data using Python/pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. DataFrames\n",
        "\n",
        "DataFrames can be thought of as Excel sheets on steroids:\n",
        "- Each row refers to an observation: (entity, purchase, review, user, ...)\n",
        "- Each column refers to an attribute of the observation (e.g. age, height, ...)\n",
        "- The first row usually has the names of each column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Creating a DataFrame\n",
        "\n",
        "# First, let's import pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# To make a DataFrame\n",
        "test_scores = [19, 18, 20, 20, 17]\n",
        "quiz_scores = [18, 17, 19, 20, 20]\n",
        "names = [\"Apostolos\", \"Aja\", \"Calai\", \"Katalina\", \"Cal\"]\n",
        "\n",
        "# Python automatically names the columns of the DataFrame according to the dictionary keys\n",
        "df = pd.DataFrame(\n",
        "    {\"test_scores\": test_scores, \"quiz_scores\": quiz_scores, \"names\": names}\n",
        ")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 Viewing DataFrames\n",
        "\n",
        "# The head() function prints the first few lines of the DataFrame\n",
        "# For DataFrames with millions of rows, this will be important...\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Similarly, the tail() function prints the last few rows\n",
        "# If your df is very small, they will be the same :)\n",
        "print(df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.3 Getting information about a DataFrame\n",
        "\n",
        "# To access any column of a DataFrame\n",
        "print(df[\"test_scores\"])\n",
        "print(type(df[\"test_scores\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df[\"names\"])\n",
        "print(type(df[\"names\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A useful way to summarize a DataFrame fast\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Types of each column\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More detailed information about the DataFrame\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How many observations (rows)\n",
        "print(df.shape[0])  # or len(df)\n",
        "# How many columns\n",
        "print(df.shape[1])  # or len(df.columns)\n",
        "# Names of rows (index)\n",
        "print(df.index.tolist())\n",
        "# Names of columns\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.4 Changing a DataFrame\n",
        "\n",
        "# You can create a new column in the DataFrame as follows\n",
        "df[\"new_column\"] = df[\"quiz_scores\"]\n",
        "print(df)\n",
        "\n",
        "# You can delete a column in the DataFrame by using drop()\n",
        "df = df.drop(\"new_column\", axis=1)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.5 Accessing subsets of your DataFrame\n",
        "\n",
        "# You can access rows and columns directly\n",
        "# In pandas, we use .loc[] for label-based indexing and .iloc[] for position-based indexing\n",
        "\n",
        "# Select specific rows and columns by position\n",
        "print(df.iloc[0:4][\"quiz_scores\"])  # rows 0-3, quiz_scores column\n",
        "print(df.iloc[[0, 1, 3]])  # rows 0, 1, 3, all columns\n",
        "print(df.iloc[0:4, 0:2])  # rows 0-3, columns 0-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can select only those rows that satisfy a condition\n",
        "\n",
        "# Select rows that have test_scores greater than 19\n",
        "print(df[df[\"test_scores\"] > 19])\n",
        "\n",
        "# Select rows with either test score > 19 OR quiz score <= 18\n",
        "print(df[(df[\"test_scores\"] > 19) | (df[\"quiz_scores\"] <= 18)])\n",
        "\n",
        "# Select rows with either test score > 19 AND quiz score <= 18\n",
        "print(df[(df[\"test_scores\"] > 19) & (df[\"quiz_scores\"] <= 18)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select rows with test score less or equal to 19\n",
        "print(df[~(df[\"test_scores\"] > 19)])  # ~ is the negation operator\n",
        "print(df[df[\"test_scores\"] <= 19])\n",
        "\n",
        "# Select rows with test scores equal to 19\n",
        "print(df[df[\"test_scores\"] == 19])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reading data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Reading CSV files\n",
        "# Reading data with Python/pandas is super easy\n",
        "# Let's load the reviews data\n",
        "\n",
        "# Load it to a DataFrame (assuming we're running from base directory)\n",
        "df = pd.read_csv(\"../data/reviews.csv\")\n",
        "print(type(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 Exploring the data\n",
        "# Let's explore it a little\n",
        "print(df.describe())\n",
        "print(df.head())\n",
        "# tail() returns the last six rows of the DataFrame\n",
        "print(df.tail())\n",
        "# len() returns the number of rows of the DataFrame\n",
        "print(len(df))\n",
        "# len(df.columns) returns the number of columns of the DataFrame\n",
        "print(len(df.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The following returns the number of rows that have \"verified\" equal to 1\n",
        "print(len(df[df[\"verified\"] == 1]))\n",
        "# How many verified reviews? (proportion)\n",
        "print(df[\"verified\"].mean())\n",
        "\n",
        "# What are the unique different possible ratings?\n",
        "print(df[\"productRating\"].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.3 Writing data\n",
        "# Let's keep only two star reviews\n",
        "df_twostar = df[df[\"productRating\"] == 2]\n",
        "# Let's write the new file\n",
        "df_twostar.to_csv(\"../temp/reviews_2star.csv\", index=False)\n",
        "\n",
        "# Super easy, right? And way way faster than Excel.\n",
        "# And, as will become apparent, way more possibilities...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 2\n",
        "\n",
        "**Topic**: We will now take a look into how to analyze data. We will also introduce pandas method chaining, which helps us write code in a more readable way\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Data\n",
        "# Load the homes dataset\n",
        "df_homes = pd.read_csv(\"../data/homes.csv\")\n",
        "\n",
        "# What is this data?\n",
        "# This data contains information about homes in a county\n",
        "# We can take a quick look at the dataset size and information\n",
        "print(len(df_homes))\n",
        "print(df_homes.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Or we can look at a summary of the data set to get some more advanced information\n",
        "print(df_homes.describe())\n",
        "\n",
        "# How many conditions?\n",
        "print(df_homes[\"condition\"].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pandas: isolating data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 The select operation\n",
        "# This operation is used to extract columns from our data by using their name\n",
        "\n",
        "# For example, let's say we want to extract the total value column\n",
        "values = df_homes[[\"totalvalue\"]]  # Double brackets return DataFrame\n",
        "print(values.mean())  # This works because values is a DataFrame\n",
        "\n",
        "print(type(values))\n",
        "\n",
        "# Alternatively, single brackets return a Series\n",
        "values_series = df_homes[\"totalvalue\"]\n",
        "print(values_series.mean())\n",
        "\n",
        "# For example let's say we want to extract more than one column\n",
        "df_new = df_homes[[\"totalvalue\", \"yearbuilt\"]]\n",
        "\n",
        "# If we want all columns except certain ones\n",
        "df_new = df_homes.drop([\"yearbuilt\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 The filter operation\n",
        "# This operation keeps only rows that satisfy a condition\n",
        "\n",
        "# Keep only houses built in 2015\n",
        "df_new = df_homes[df_homes[\"yearbuilt\"] == 2015]\n",
        "\n",
        "# Keep houses not built in 2015\n",
        "df_new = df_homes[df_homes[\"yearbuilt\"] != 2015]\n",
        "\n",
        "# Keep houses built after 2015\n",
        "df_new = df_homes[df_homes[\"yearbuilt\"] > 2015]\n",
        "\n",
        "# Keep houses that were built in 2011, 2013, or 2015\n",
        "df_new = df_homes[df_homes[\"yearbuilt\"].isin([2011, 2013, 2015])]\n",
        "# Keep houses that are either in Scottsville or Crozet\n",
        "df_new = df_homes[df_homes[\"city\"].isin([\"SCOTTSVILLE\", \"CROZET\"])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep houses with the maximum number of bedrooms\n",
        "max_bedrooms = df_homes[\"bedroom\"].max()\n",
        "df_new = df_homes[df_homes[\"bedroom\"] == max_bedrooms]\n",
        "# Alternatively\n",
        "df_new = df_homes[df_homes[\"bedroom\"] == df_homes[\"bedroom\"].max()]\n",
        "\n",
        "# Multiple conditions\n",
        "df_new = df_homes[\n",
        "    (df_homes[\"city\"] == \"CROZET\") & (df_homes[\"finsqft\"] > df_homes[\"finsqft\"].mean())\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.3 The sort operation\n",
        "# This operation helps us sort according to whatever we want\n",
        "df_new = df_homes.sort_values(\"finsqft\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pandas: method chaining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Chaining operations\n",
        "# Sometimes we want to perform many operations on a dataset\n",
        "# For example, let's say we want to (i) only select houses in Crozet\n",
        "# (ii) only keep the \"totalvalue\", and \"lotsize\" columns, and\n",
        "# (iii) sort our data by decreasing lotsize order\n",
        "\n",
        "# We could do it step by step:\n",
        "df_crozet = df_homes[df_homes[\"city\"] == \"CROZET\"]\n",
        "df_crozet = df_crozet[[\"totalvalue\", \"lotsize\"]]\n",
        "df_crozet = df_crozet.sort_values(\"lotsize\", ascending=False)\n",
        "print(df_crozet.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Or we can chain the operations together:\n",
        "df_crozet_2 = df_homes[df_homes[\"city\"] == \"CROZET\"][  # Filter for Crozet\n",
        "    [\"totalvalue\", \"lotsize\"]\n",
        "].sort_values(\"lotsize\", ascending=False)\n",
        "\n",
        "# Method chaining makes code more readable and follows the data flow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Pandas: deriving data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Creating new columns\n",
        "# We can create new columns using assignment\n",
        "\n",
        "# Create a copy of the data to work with\n",
        "df_new = df_homes.copy()\n",
        "\n",
        "# Create a new column by dividing two existing columns\n",
        "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
        "\n",
        "# Select only the columns we want and sort by value per square foot\n",
        "df_new = df_new[[\"yearbuilt\", \"condition\", \"finsqft\", \"totalvalue\", \"city\", \"value_sqft\"]]\n",
        "df_new = df_new.sort_values(\"value_sqft\", ascending=False)\n",
        "\n",
        "print(df_new.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can also create conditional columns\n",
        "# First, let's create the value_sqft column again\n",
        "df_new = df_homes.copy()\n",
        "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
        "\n",
        "# Create a column that shows if a house has high value per sqft\n",
        "median_value_sqft = df_new[\"value_sqft\"].median()\n",
        "df_new[\"high_value_sqft\"] = df_new[\"value_sqft\"] > median_value_sqft\n",
        "\n",
        "# Select columns and sort\n",
        "df_new = df_new[[\"yearbuilt\", \"condition\", \"finsqft\", \"totalvalue\", \"city\", \"value_sqft\", \"high_value_sqft\"]]\n",
        "df_new = df_new.sort_values(\"value_sqft\", ascending=False)\n",
        "\n",
        "print(df_new.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating multiple new columns at once\n",
        "df_new = df_homes.copy()\n",
        "\n",
        "# Create value per square foot\n",
        "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
        "\n",
        "# Create remodel indicator (1 if remodeled, 0 if not)\n",
        "df_new[\"remodel\"] = (df_new[\"yearremodeled\"] > 0).astype(int)\n",
        "\n",
        "# Select only the columns we want and sort\n",
        "df_new = df_new[[\"value_sqft\", \"remodel\", \"city\"]]\n",
        "df_new = df_new.sort_values(\"value_sqft\")\n",
        "\n",
        "print(df_new.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 Summary statistics\n",
        "# This computes summary statistics and creates a new DataFrame\n",
        "\n",
        "# First, filter houses with yearbuilt info\n",
        "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0]\n",
        "\n",
        "# Compute summary statistics\n",
        "df_homes_stats = df_homes_filtered.agg({\"yearbuilt\": [\"min\", \"max\", \"count\", \"mean\", \"median\"]}).round(2)\n",
        "\n",
        "print(df_homes_stats)\n",
        "\n",
        "# Alternative approach using describe\n",
        "df_homes_stats = df_homes_filtered[\"yearbuilt\"].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 Group by operations\n",
        "# This function groups cases by common values of one or more columns\n",
        "\n",
        "# First, filter houses with yearbuilt info\n",
        "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0]\n",
        "\n",
        "# Group by city and compute summary statistics\n",
        "df_homes_stats = (\n",
        "    df_homes_filtered\n",
        "    .groupby(\"city\")[\"yearbuilt\"]\n",
        "    .agg([\"min\", \"max\", \"count\", \"mean\", \"median\"])\n",
        "    .round(2)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(df_homes_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you don't want to obtain summaries but only within-group quantities\n",
        "# First, filter houses with yearbuilt info\n",
        "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0].copy()\n",
        "\n",
        "# Calculate median year built by city\n",
        "median_by_city = df_homes_filtered.groupby(\"city\")[\"yearbuilt\"].median()\n",
        "\n",
        "# Add the median back to our dataframe\n",
        "df_homes_filtered[\"median_yearbuilt\"] = df_homes_filtered[\"city\"].map(median_by_city)\n",
        "\n",
        "# Create a new column indicating if house is newer than city median\n",
        "df_homes_filtered[\"new\"] = (df_homes_filtered[\"yearbuilt\"] >= df_homes_filtered[\"median_yearbuilt\"]).astype(int)\n",
        "\n",
        "# Select only the columns we want\n",
        "df_homes_stats = df_homes_filtered[[\"yearbuilt\", \"condition\", \"finsqft\", \"city\", \"median_yearbuilt\", \"new\"]]\n",
        "\n",
        "print(df_homes_stats.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can group by more than one variable\n",
        "# Group by both city and the \"new\" indicator we just created\n",
        "df_homes_stats = (\n",
        "    df_homes_filtered\n",
        "    .groupby([\"city\", \"new\"])[\"yearbuilt\"]\n",
        "    .agg([\"min\", \"max\", \"count\", \"mean\", \"median\"])\n",
        "    .round(2)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(df_homes_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ‰ FIN!!\n",
        "\n",
        "### Recap:\n",
        "We covered the most useful analysis data structure in Python -- the DataFrame. We'll use that structure a lot in the next few weeks.\n",
        "\n",
        "### Next week:\n",
        "We will learn how we can visualize data using Python\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
