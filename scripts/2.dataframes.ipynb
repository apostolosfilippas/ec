{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: E-Commerce\n",
    "\n",
    "### ðŸ“‹ **Topic**: DataFrames and Analyzing Data with Python\n",
    "\n",
    "ðŸš« **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1\n",
    "\n",
    "**Topic**: We will learn the most useful data structure in Python: the DataFrame. We will also see how easy it is to read and write data using Python/pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataFrames\n",
    "\n",
    "DataFrames can be thought of as Excel sheets on steroids:\n",
    "- Each row refers to an observation: (entity, purchase, review, user, ...)\n",
    "- Each column refers to an attribute of the observation (e.g. age, height, ...)\n",
    "- The first row usually has the names of each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.191412Z",
     "iopub.status.busy": "2025-08-27T19:51:05.191121Z",
     "iopub.status.idle": "2025-08-27T19:51:05.462458Z",
     "shell.execute_reply": "2025-08-27T19:51:05.462221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "2           20           19      Calai\n",
      "3           20           20   Katalina\n",
      "4           17           20        Cal\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Creating a DataFrame\n",
    "\n",
    "# First, let's import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To make a DataFrame\n",
    "test_scores = [19, 18, 20, 20, 17]\n",
    "quiz_scores = [18, 17, 19, 20, 20]\n",
    "names = [\"Apostolos\", \"Aja\", \"Calai\", \"Katalina\", \"Cal\"]\n",
    "\n",
    "# Python automatically names the columns of the DataFrame according to the dictionary keys\n",
    "df = pd.DataFrame(\n",
    "    {\"test_scores\": test_scores, \"quiz_scores\": quiz_scores, \"names\": names}\n",
    ")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.479812Z",
     "iopub.status.busy": "2025-08-27T19:51:05.479692Z",
     "iopub.status.idle": "2025-08-27T19:51:05.481667Z",
     "shell.execute_reply": "2025-08-27T19:51:05.481433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "2           20           19      Calai\n",
      "3           20           20   Katalina\n",
      "4           17           20        Cal\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Viewing DataFrames\n",
    "\n",
    "# The head() function prints the first few lines of the DataFrame\n",
    "# For DataFrames with millions of rows, this will be important...\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.482633Z",
     "iopub.status.busy": "2025-08-27T19:51:05.482568Z",
     "iopub.status.idle": "2025-08-27T19:51:05.484319Z",
     "shell.execute_reply": "2025-08-27T19:51:05.484117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "2           20           19      Calai\n",
      "3           20           20   Katalina\n",
      "4           17           20        Cal\n"
     ]
    }
   ],
   "source": [
    "# Similarly, the tail() function prints the last few rows\n",
    "# If your df is very small, they will be the same :)\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.485268Z",
     "iopub.status.busy": "2025-08-27T19:51:05.485200Z",
     "iopub.status.idle": "2025-08-27T19:51:05.486845Z",
     "shell.execute_reply": "2025-08-27T19:51:05.486633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19\n",
      "1    18\n",
      "2    20\n",
      "3    20\n",
      "4    17\n",
      "Name: test_scores, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Getting information about a DataFrame\n",
    "\n",
    "# To access any column of a DataFrame\n",
    "print(df[\"test_scores\"])\n",
    "print(type(df[\"test_scores\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.487750Z",
     "iopub.status.busy": "2025-08-27T19:51:05.487684Z",
     "iopub.status.idle": "2025-08-27T19:51:05.489232Z",
     "shell.execute_reply": "2025-08-27T19:51:05.489042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Apostolos\n",
      "1          Aja\n",
      "2        Calai\n",
      "3     Katalina\n",
      "4          Cal\n",
      "Name: names, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(df[\"names\"])\n",
    "print(type(df[\"names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.490163Z",
     "iopub.status.busy": "2025-08-27T19:51:05.490088Z",
     "iopub.status.idle": "2025-08-27T19:51:05.493636Z",
     "shell.execute_reply": "2025-08-27T19:51:05.493442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       test_scores  quiz_scores\n",
      "count      5.00000      5.00000\n",
      "mean      18.80000     18.80000\n",
      "std        1.30384      1.30384\n",
      "min       17.00000     17.00000\n",
      "25%       18.00000     18.00000\n",
      "50%       19.00000     19.00000\n",
      "75%       20.00000     20.00000\n",
      "max       20.00000     20.00000\n"
     ]
    }
   ],
   "source": [
    "# A useful way to summarize a DataFrame fast\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.494482Z",
     "iopub.status.busy": "2025-08-27T19:51:05.494423Z",
     "iopub.status.idle": "2025-08-27T19:51:05.495869Z",
     "shell.execute_reply": "2025-08-27T19:51:05.495699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_scores     int64\n",
      "quiz_scores     int64\n",
      "names          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Types of each column\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.496753Z",
     "iopub.status.busy": "2025-08-27T19:51:05.496683Z",
     "iopub.status.idle": "2025-08-27T19:51:05.501273Z",
     "shell.execute_reply": "2025-08-27T19:51:05.501081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   test_scores  5 non-null      int64 \n",
      " 1   quiz_scores  5 non-null      int64 \n",
      " 2   names        5 non-null      object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 252.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# More detailed information about the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.502194Z",
     "iopub.status.busy": "2025-08-27T19:51:05.502134Z",
     "iopub.status.idle": "2025-08-27T19:51:05.503712Z",
     "shell.execute_reply": "2025-08-27T19:51:05.503507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "[0, 1, 2, 3, 4]\n",
      "['test_scores', 'quiz_scores', 'names']\n"
     ]
    }
   ],
   "source": [
    "# How many observations (rows)\n",
    "print(df.shape[0])  # or len(df)\n",
    "# How many columns\n",
    "print(df.shape[1])  # or len(df.columns)\n",
    "# Names of rows (index)\n",
    "print(df.index.tolist())\n",
    "# Names of columns\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.504589Z",
     "iopub.status.busy": "2025-08-27T19:51:05.504531Z",
     "iopub.status.idle": "2025-08-27T19:51:05.507155Z",
     "shell.execute_reply": "2025-08-27T19:51:05.506931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores      names  new_column\n",
      "0           19           18  Apostolos          18\n",
      "1           18           17        Aja          17\n",
      "2           20           19      Calai          19\n",
      "3           20           20   Katalina          20\n",
      "4           17           20        Cal          20\n",
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "2           20           19      Calai\n",
      "3           20           20   Katalina\n",
      "4           17           20        Cal\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Changing a DataFrame\n",
    "\n",
    "# You can create a new column in the DataFrame as follows\n",
    "df[\"new_column\"] = df[\"quiz_scores\"]\n",
    "print(df)\n",
    "\n",
    "# You can delete a column in the DataFrame by using drop()\n",
    "df = df.drop(\"new_column\", axis=1)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.508185Z",
     "iopub.status.busy": "2025-08-27T19:51:05.508104Z",
     "iopub.status.idle": "2025-08-27T19:51:05.510572Z",
     "shell.execute_reply": "2025-08-27T19:51:05.510385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18\n",
      "1    17\n",
      "2    19\n",
      "3    20\n",
      "Name: quiz_scores, dtype: int64\n",
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "3           20           20   Katalina\n",
      "   test_scores  quiz_scores\n",
      "0           19           18\n",
      "1           18           17\n",
      "2           20           19\n",
      "3           20           20\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Accessing subsets of your DataFrame\n",
    "\n",
    "# You can access rows and columns directly\n",
    "# In pandas, we use .loc[] for label-based indexing and .iloc[] for position-based indexing\n",
    "\n",
    "# Select specific rows and columns by position\n",
    "print(df.iloc[0:4][\"quiz_scores\"])  # rows 0-3, quiz_scores column\n",
    "print(df.iloc[[0, 1, 3]])  # rows 0, 1, 3, all columns\n",
    "print(df.iloc[0:4, 0:2])  # rows 0-3, columns 0-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.511531Z",
     "iopub.status.busy": "2025-08-27T19:51:05.511475Z",
     "iopub.status.idle": "2025-08-27T19:51:05.514186Z",
     "shell.execute_reply": "2025-08-27T19:51:05.513995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores     names\n",
      "2           20           19     Calai\n",
      "3           20           20  Katalina\n",
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "2           20           19      Calai\n",
      "3           20           20   Katalina\n",
      "Empty DataFrame\n",
      "Columns: [test_scores, quiz_scores, names]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# You can select only those rows that satisfy a condition\n",
    "\n",
    "# Select rows that have test_scores greater than 19\n",
    "print(df[df[\"test_scores\"] > 19])\n",
    "\n",
    "# Select rows with either test score > 19 OR quiz score <= 18\n",
    "print(df[(df[\"test_scores\"] > 19) | (df[\"quiz_scores\"] <= 18)])\n",
    "\n",
    "# Select rows with either test score > 19 AND quiz score <= 18\n",
    "print(df[(df[\"test_scores\"] > 19) & (df[\"quiz_scores\"] <= 18)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.515155Z",
     "iopub.status.busy": "2025-08-27T19:51:05.515094Z",
     "iopub.status.idle": "2025-08-27T19:51:05.517611Z",
     "shell.execute_reply": "2025-08-27T19:51:05.517403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "4           17           20        Cal\n",
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n",
      "1           18           17        Aja\n",
      "4           17           20        Cal\n",
      "   test_scores  quiz_scores      names\n",
      "0           19           18  Apostolos\n"
     ]
    }
   ],
   "source": [
    "# Select rows with test score less or equal to 19\n",
    "print(df[~(df[\"test_scores\"] > 19)])  # ~ is the negation operator\n",
    "print(df[df[\"test_scores\"] <= 19])\n",
    "\n",
    "# Select rows with test scores equal to 19\n",
    "print(df[df[\"test_scores\"] == 19])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.518587Z",
     "iopub.status.busy": "2025-08-27T19:51:05.518524Z",
     "iopub.status.idle": "2025-08-27T19:51:05.560680Z",
     "shell.execute_reply": "2025-08-27T19:51:05.560464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Reading CSV files\n",
    "# Reading data with Python/pandas is super easy\n",
    "# Let's load the reviews data\n",
    "\n",
    "# Load it to a DataFrame (assuming we're running from base directory)\n",
    "df = pd.read_csv(\"../data/reviews.csv\")\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.561711Z",
     "iopub.status.busy": "2025-08-27T19:51:05.561627Z",
     "iopub.status.idle": "2025-08-27T19:51:05.568626Z",
     "shell.execute_reply": "2025-08-27T19:51:05.568433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       helpfulVotes    prcHelpful    totalVotes  productRating      verified\n",
      "count  10000.000000  10000.000000  10000.000000   10000.000000  10000.000000\n",
      "mean       3.948200      0.871846      4.871800       4.072200      0.734900\n",
      "std       26.236687      0.280440     27.534389       1.331076      0.441409\n",
      "min       -1.000000      0.000000     -1.000000       1.000000      0.000000\n",
      "25%       -1.000000      0.967000     -1.000000       4.000000      0.000000\n",
      "50%       -1.000000      1.000000     -1.000000       5.000000      1.000000\n",
      "75%        2.000000      1.000000      3.000000       5.000000      1.000000\n",
      "max     1410.000000      1.000000   1417.000000       5.000000      1.000000\n",
      "         reviewId      reviewerId        asin  \\\n",
      "0  R1001D7IWN3HGH   AYGHDZICPFM42  B0011ZK6OS   \n",
      "1  R1002DBICCTX81   AHAKLV81NL2MA  B00AQDG7YE   \n",
      "2  R1003U8MAJM7EG  A1BWH6MOLMHTIO  B00UKMBSE0   \n",
      "3  R10052A11TEKY5  A12T9H67BA5R0K  B00393THEK   \n",
      "4  R1006VVT7S8G2G  A17Z6JA6JUNF66  B00395YA90   \n",
      "\n",
      "                                              review  \\\n",
      "0  I can't write a very technical review.  I just...   \n",
      "1  This little point and shoot can barely fit in ...   \n",
      "2  I was not sure if I should go for a GoPro, and...   \n",
      "3  I would never go without a backup and this one...   \n",
      "4  Seems to offer lots of features plus quality. ...   \n",
      "\n",
      "                                               title          dateWritten  \\\n",
      "0                                       great camera  2008-12-17 00:00:00   \n",
      "1                                               Wow!  2013-09-21 00:00:00   \n",
      "2  I used it to snorkel back in the Caribe and ev...  2014-08-15 00:00:00   \n",
      "3                                     Great product!  2013-10-12 00:00:00   \n",
      "4                            Panasonic Lumix DMC ZS5  2010-09-05 00:00:00   \n",
      "\n",
      "   helpfulVotes  prcHelpful  totalVotes  productRating  verified badges  \n",
      "0            -1         1.0          -1            5.0         0    NaN  \n",
      "1             3         1.0           3            5.0         1    NaN  \n",
      "2            -1         1.0          -1            5.0         1    NaN  \n",
      "3            -1         1.0          -1            5.0         1    NaN  \n",
      "4            -1         1.0          -1            4.0         1    NaN  \n",
      "            reviewId      reviewerId        asin  \\\n",
      "9995   R175PKL1JS96M   A2OF14U27NJY7  B0090SLJDU   \n",
      "9996  R175PV5GJ74QGS  A22NE4VSITL10W  B00HQ4W326   \n",
      "9997  R175T83I6ST0HL   AE3ZCISXLXB7Z  B004DEKH84   \n",
      "9998  R175VGA5M31CO3  A1AGU2SE3L8UAH  B0073AVSKG   \n",
      "9999  R175VIVCB71T85  A1K6XKO9T0PK5P  B006UMM15O   \n",
      "\n",
      "                                                 review  \\\n",
      "9995  I got really sick of the iphone camera's crapp...   \n",
      "9996  Great Camera, excellent for an amateur photogr...   \n",
      "9997  much more comfortable than the one that came w...   \n",
      "9998  There are things in this package that are grea...   \n",
      "9999  This is a great little camera that packs a pun...   \n",
      "\n",
      "                                                  title          dateWritten  \\\n",
      "9995  LOVE it! Perfect for having an alternative to ...  2012-12-12 00:00:00   \n",
      "9996              Great Camera for Amateur Photographer  2014-12-29 00:00:00   \n",
      "9997                                    nice neck strap  2013-09-10 00:00:00   \n",
      "9998                       Some items good, others not.  2014-11-27 00:00:00   \n",
      "9999                       Great camera, fast shipping!  2013-09-06 00:00:00   \n",
      "\n",
      "      helpfulVotes  prcHelpful  totalVotes  productRating  verified badges  \n",
      "9995            -1         1.0          -1            5.0         1    NaN  \n",
      "9996            -1         1.0          -1            5.0         1    NaN  \n",
      "9997            -1         1.0          -1            5.0         1    NaN  \n",
      "9998            -1         1.0          -1            3.0         1    NaN  \n",
      "9999            -1         1.0          -1            5.0         1    NaN  \n",
      "10000\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Exploring the data\n",
    "# Let's explore it a little\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "# tail() returns the last six rows of the DataFrame\n",
    "print(df.tail())\n",
    "# len() returns the number of rows of the DataFrame\n",
    "print(len(df))\n",
    "# len(df.columns) returns the number of columns of the DataFrame\n",
    "print(len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.569652Z",
     "iopub.status.busy": "2025-08-27T19:51:05.569575Z",
     "iopub.status.idle": "2025-08-27T19:51:05.572473Z",
     "shell.execute_reply": "2025-08-27T19:51:05.572263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7349\n",
      "0.7349\n",
      "[5. 4. 3. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# The following returns the number of rows that have \"verified\" equal to 1\n",
    "print(len(df[df[\"verified\"] == 1]))\n",
    "# How many verified reviews? (proportion)\n",
    "print(df[\"verified\"].mean())\n",
    "\n",
    "# What are the unique different possible ratings?\n",
    "print(df[\"productRating\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.573532Z",
     "iopub.status.busy": "2025-08-27T19:51:05.573452Z",
     "iopub.status.idle": "2025-08-27T19:51:05.580716Z",
     "shell.execute_reply": "2025-08-27T19:51:05.580499Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.3 Writing data\n",
    "# Let's keep only two star reviews\n",
    "df_twostar = df[df[\"productRating\"] == 2]\n",
    "# Let's write the new file\n",
    "df_twostar.to_csv(\"../temp/reviews_2star.csv\", index=False)\n",
    "\n",
    "# Super easy, right? And way way faster than Excel.\n",
    "# And, as will become apparent, way more possibilities...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2\n",
    "\n",
    "**Topic**: We will now take a look into how to analyze data. We will also introduce pandas method chaining, which helps us write code in a more readable way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.581659Z",
     "iopub.status.busy": "2025-08-27T19:51:05.581600Z",
     "iopub.status.idle": "2025-08-27T19:51:05.619308Z",
     "shell.execute_reply": "2025-08-27T19:51:05.619107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32746\n",
      "['tmp', 'yearbuilt', 'yearremodeled', 'usecode', 'condition', 'finsqft', 'cooling', 'fp_num', 'bedroom', 'fullbath', 'halfbath', 'totalrooms', 'city', 'zip', 'lotsize', 'landvalue', 'improvementsvalue', 'totalvalue', 'lastsaleprice', 'lastsaledate', 'age', 'med_age', 'fp', 'landuse', 'insub', 'remodel']\n"
     ]
    }
   ],
   "source": [
    "# 1. Data\n",
    "# Load the homes dataset\n",
    "df_homes = pd.read_csv(\"../data/homes.csv\")\n",
    "\n",
    "# What is this data?\n",
    "# This data contains information about homes in a county\n",
    "# We can take a quick look at the dataset size and information\n",
    "print(len(df_homes))\n",
    "print(df_homes.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.620284Z",
     "iopub.status.busy": "2025-08-27T19:51:05.620223Z",
     "iopub.status.idle": "2025-08-27T19:51:05.636812Z",
     "shell.execute_reply": "2025-08-27T19:51:05.636618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          yearbuilt  yearremodeled       finsqft        fp_num       bedroom  \\\n",
      "count  32746.000000   32746.000000  32746.000000  32746.000000  32746.000000   \n",
      "mean    1956.130306     139.372473   1944.679442      0.933702      3.232792   \n",
      "std      231.720697     508.767332    933.221573      0.873719      0.963218   \n",
      "min        0.000000       0.000000    144.000000      0.000000      0.000000   \n",
      "25%     1973.000000       0.000000   1278.000000      0.000000      3.000000   \n",
      "50%     1987.000000       0.000000   1713.000000      1.000000      3.000000   \n",
      "75%     2000.000000       0.000000   2411.000000      1.000000      4.000000   \n",
      "max     2016.000000    2016.000000   8982.000000     13.000000     20.000000   \n",
      "\n",
      "           fullbath      halfbath    totalrooms           zip       lotsize  \\\n",
      "count  32746.000000  32746.000000  32746.000000  32490.000000  32746.000000   \n",
      "mean       2.205460      0.565321      6.630031  22971.655894      4.631110   \n",
      "std        0.936618      0.578771      2.497755    301.841535     22.102507   \n",
      "min        0.000000      0.000000      0.000000  22901.000000      0.000000   \n",
      "25%        2.000000      0.000000      5.000000  22901.000000      0.096000   \n",
      "50%        2.000000      1.000000      7.000000  22911.000000      0.537000   \n",
      "75%        3.000000      1.000000      8.000000  22932.000000      2.570000   \n",
      "max       11.000000      5.000000     87.000000  24590.000000   1067.150000   \n",
      "\n",
      "          landvalue  improvementsvalue    totalvalue  lastsaleprice  \\\n",
      "count  3.274600e+04       3.274600e+04  3.274600e+04   3.274500e+04   \n",
      "mean   1.328489e+05       2.490682e+05  3.819171e+05   3.900473e+05   \n",
      "std    1.858939e+05       2.394328e+05  3.573200e+05   1.438328e+06   \n",
      "min    1.200000e+03       0.000000e+00  9.500000e+03   0.000000e+00   \n",
      "25%    6.600000e+04       1.219000e+05  1.959000e+05   0.000000e+00   \n",
      "50%    1.050000e+05       1.920000e+05  2.999000e+05   1.570000e+05   \n",
      "75%    1.459000e+05       2.948000e+05  4.437000e+05   3.230000e+05   \n",
      "max    1.050170e+07       9.638500e+06  1.135230e+07   4.893700e+07   \n",
      "\n",
      "                age       med_age            fp       landuse         insub  \\\n",
      "count  32745.000000  32745.000000  32746.000000  32746.000000  32746.000000   \n",
      "mean      32.773553     28.078394      0.694925      0.049716      0.713156   \n",
      "std       27.161985      5.192818      0.460446      0.217361      0.452295   \n",
      "min        0.000000     17.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.000000     28.000000      0.000000      0.000000      0.000000   \n",
      "50%       28.000000     28.000000      1.000000      0.000000      1.000000   \n",
      "75%       43.000000     28.000000      1.000000      0.000000      1.000000   \n",
      "max      348.000000     50.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "            remodel  \n",
      "count  32746.000000  \n",
      "mean       0.069871  \n",
      "std        0.254934  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max        1.000000  \n",
      "['Average' 'Fair' 'Good' 'Poor' nan 'Substandard' 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "# Or we can look at a summary of the data set to get some more advanced information\n",
    "print(df_homes.describe())\n",
    "\n",
    "# How many conditions?\n",
    "print(df_homes[\"condition\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas: isolating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.637853Z",
     "iopub.status.busy": "2025-08-27T19:51:05.637785Z",
     "iopub.status.idle": "2025-08-27T19:51:05.641789Z",
     "shell.execute_reply": "2025-08-27T19:51:05.641598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalvalue    381917.073841\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "381917.07384107984\n"
     ]
    }
   ],
   "source": [
    "# 2.1 The select operation\n",
    "# This operation is used to extract columns from our data by using their name\n",
    "\n",
    "# For example, let's say we want to extract the total value column\n",
    "values = df_homes[[\"totalvalue\"]]  # Double brackets return DataFrame\n",
    "print(values.mean())  # This works because values is a DataFrame\n",
    "\n",
    "print(type(values))\n",
    "\n",
    "# Alternatively, single brackets return a Series\n",
    "values_series = df_homes[\"totalvalue\"]\n",
    "print(values_series.mean())\n",
    "\n",
    "# For example let's say we want to extract more than one column\n",
    "df_new = df_homes[[\"totalvalue\", \"yearbuilt\"]]\n",
    "\n",
    "# If we want all columns except certain ones\n",
    "df_new = df_homes.drop([\"yearbuilt\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.642724Z",
     "iopub.status.busy": "2025-08-27T19:51:05.642660Z",
     "iopub.status.idle": "2025-08-27T19:51:05.649897Z",
     "shell.execute_reply": "2025-08-27T19:51:05.649678Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 The filter operation\n",
    "# This operation keeps only rows that satisfy a condition\n",
    "\n",
    "# Keep only houses built in 2015\n",
    "df_new = df_homes[df_homes[\"yearbuilt\"] == 2015]\n",
    "\n",
    "# Keep houses not built in 2015\n",
    "df_new = df_homes[df_homes[\"yearbuilt\"] != 2015]\n",
    "\n",
    "# Keep houses built after 2015\n",
    "df_new = df_homes[df_homes[\"yearbuilt\"] > 2015]\n",
    "\n",
    "# Keep houses that were built in 2011, 2013, or 2015\n",
    "df_new = df_homes[df_homes[\"yearbuilt\"].isin([2011, 2013, 2015])]\n",
    "# Keep houses that are either in Scottsville or Crozet\n",
    "df_new = df_homes[df_homes[\"city\"].isin([\"SCOTTSVILLE\", \"CROZET\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.650842Z",
     "iopub.status.busy": "2025-08-27T19:51:05.650778Z",
     "iopub.status.idle": "2025-08-27T19:51:05.653998Z",
     "shell.execute_reply": "2025-08-27T19:51:05.653769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep houses with the maximum number of bedrooms\n",
    "max_bedrooms = df_homes[\"bedroom\"].max()\n",
    "df_new = df_homes[df_homes[\"bedroom\"] == max_bedrooms]\n",
    "# Alternatively\n",
    "df_new = df_homes[df_homes[\"bedroom\"] == df_homes[\"bedroom\"].max()]\n",
    "\n",
    "# Multiple conditions\n",
    "df_new = df_homes[\n",
    "    (df_homes[\"city\"] == \"CROZET\") & (df_homes[\"finsqft\"] > df_homes[\"finsqft\"].mean())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.654913Z",
     "iopub.status.busy": "2025-08-27T19:51:05.654852Z",
     "iopub.status.idle": "2025-08-27T19:51:05.659064Z",
     "shell.execute_reply": "2025-08-27T19:51:05.658859Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.3 The sort operation\n",
    "# This operation helps us sort according to whatever we want\n",
    "df_new = df_homes.sort_values(\"finsqft\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandas: method chaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.660046Z",
     "iopub.status.busy": "2025-08-27T19:51:05.659985Z",
     "iopub.status.idle": "2025-08-27T19:51:05.663617Z",
     "shell.execute_reply": "2025-08-27T19:51:05.663430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       totalvalue  lotsize\n",
      "30915     1975300  620.430\n",
      "20923     2391000  453.893\n",
      "152       1111500  288.139\n",
      "20960      740800  261.711\n",
      "30916     1260700  231.100\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Chaining operations\n",
    "# Sometimes we want to perform many operations on a dataset\n",
    "# For example, let's say we want to (i) only select houses in Crozet\n",
    "# (ii) only keep the \"totalvalue\", and \"lotsize\" columns, and\n",
    "# (iii) sort our data by decreasing lotsize order\n",
    "\n",
    "# We could do it step by step:\n",
    "df_crozet = df_homes[df_homes[\"city\"] == \"CROZET\"]\n",
    "df_crozet = df_crozet[[\"totalvalue\", \"lotsize\"]]\n",
    "df_crozet = df_crozet.sort_values(\"lotsize\", ascending=False)\n",
    "print(df_crozet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.664616Z",
     "iopub.status.busy": "2025-08-27T19:51:05.664548Z",
     "iopub.status.idle": "2025-08-27T19:51:05.667498Z",
     "shell.execute_reply": "2025-08-27T19:51:05.667306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Or we can chain the operations together:\n",
    "df_crozet_2 = df_homes[df_homes[\"city\"] == \"CROZET\"][  # Filter for Crozet\n",
    "    [\"totalvalue\", \"lotsize\"]\n",
    "].sort_values(\"lotsize\", ascending=False)\n",
    "\n",
    "# Method chaining makes code more readable and follows the data flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pandas: deriving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.668495Z",
     "iopub.status.busy": "2025-08-27T19:51:05.668428Z",
     "iopub.status.idle": "2025-08-27T19:51:05.675203Z",
     "shell.execute_reply": "2025-08-27T19:51:05.675007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yearbuilt condition  finsqft  totalvalue             city   value_sqft\n",
      "17147          0   Average     1210    10351200          KESWICK  8554.710744\n",
      "19585       1935   Average      475     3931500            OTHER  8276.842105\n",
      "16218       1962   Average     1590    11352300  CHARLOTTESVILLE  7139.811321\n",
      "25347       1934   Average      600     3931500            OTHER  6552.500000\n",
      "8079           0      Fair      731     4153300            OTHER  5681.668947\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Creating new columns\n",
    "# We can create new columns using assignment\n",
    "\n",
    "# Create a copy of the data to work with\n",
    "df_new = df_homes.copy()\n",
    "\n",
    "# Create a new column by dividing two existing columns\n",
    "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
    "\n",
    "# Select only the columns we want and sort by value per square foot\n",
    "df_new = df_new[[\"yearbuilt\", \"condition\", \"finsqft\", \"totalvalue\", \"city\", \"value_sqft\"]]\n",
    "df_new = df_new.sort_values(\"value_sqft\", ascending=False)\n",
    "\n",
    "print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.676150Z",
     "iopub.status.busy": "2025-08-27T19:51:05.676089Z",
     "iopub.status.idle": "2025-08-27T19:51:05.683603Z",
     "shell.execute_reply": "2025-08-27T19:51:05.683367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yearbuilt condition  finsqft  totalvalue             city   value_sqft  \\\n",
      "17147          0   Average     1210    10351200          KESWICK  8554.710744   \n",
      "19585       1935   Average      475     3931500            OTHER  8276.842105   \n",
      "16218       1962   Average     1590    11352300  CHARLOTTESVILLE  7139.811321   \n",
      "25347       1934   Average      600     3931500            OTHER  6552.500000   \n",
      "8079           0      Fair      731     4153300            OTHER  5681.668947   \n",
      "\n",
      "       high_value_sqft  \n",
      "17147             True  \n",
      "19585             True  \n",
      "16218             True  \n",
      "25347             True  \n",
      "8079              True  \n"
     ]
    }
   ],
   "source": [
    "# We can also create conditional columns\n",
    "# First, let's create the value_sqft column again\n",
    "df_new = df_homes.copy()\n",
    "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
    "\n",
    "# Create a column that shows if a house has high value per sqft\n",
    "median_value_sqft = df_new[\"value_sqft\"].median()\n",
    "df_new[\"high_value_sqft\"] = df_new[\"value_sqft\"] > median_value_sqft\n",
    "\n",
    "# Select columns and sort\n",
    "df_new = df_new[[\"yearbuilt\", \"condition\", \"finsqft\", \"totalvalue\", \"city\", \"value_sqft\", \"high_value_sqft\"]]\n",
    "df_new = df_new.sort_values(\"value_sqft\", ascending=False)\n",
    "\n",
    "print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.684521Z",
     "iopub.status.busy": "2025-08-27T19:51:05.684462Z",
     "iopub.status.idle": "2025-08-27T19:51:05.690724Z",
     "shell.execute_reply": "2025-08-27T19:51:05.690510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       value_sqft  remodel             city\n",
      "31112    7.620818        0  CHARLOTTESVILLE\n",
      "4230    10.772358        0           ESMONT\n",
      "28570   11.020882        0            OTHER\n",
      "18469   12.104489        0            OTHER\n",
      "19276   13.699495        0            OTHER\n"
     ]
    }
   ],
   "source": [
    "# Creating multiple new columns at once\n",
    "df_new = df_homes.copy()\n",
    "\n",
    "# Create value per square foot\n",
    "df_new[\"value_sqft\"] = df_new[\"totalvalue\"] / df_new[\"finsqft\"]\n",
    "\n",
    "# Create remodel indicator (1 if remodeled, 0 if not)\n",
    "df_new[\"remodel\"] = (df_new[\"yearremodeled\"] > 0).astype(int)\n",
    "\n",
    "# Select only the columns we want and sort\n",
    "df_new = df_new[[\"value_sqft\", \"remodel\", \"city\"]]\n",
    "df_new = df_new.sort_values(\"value_sqft\")\n",
    "\n",
    "print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.691711Z",
     "iopub.status.busy": "2025-08-27T19:51:05.691644Z",
     "iopub.status.idle": "2025-08-27T19:51:05.696987Z",
     "shell.execute_reply": "2025-08-27T19:51:05.696730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        yearbuilt\n",
      "min        1668.0\n",
      "max        2016.0\n",
      "count     32299.0\n",
      "mean       1983.2\n",
      "median     1988.0\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Summary statistics\n",
    "# This computes summary statistics and creates a new DataFrame\n",
    "\n",
    "# First, filter houses with yearbuilt info\n",
    "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0]\n",
    "\n",
    "# Compute summary statistics\n",
    "df_homes_stats = df_homes_filtered.agg({\"yearbuilt\": [\"min\", \"max\", \"count\", \"mean\", \"median\"]}).round(2)\n",
    "\n",
    "print(df_homes_stats)\n",
    "\n",
    "# Alternative approach using describe\n",
    "df_homes_stats = df_homes_filtered[\"yearbuilt\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.697936Z",
     "iopub.status.busy": "2025-08-27T19:51:05.697860Z",
     "iopub.status.idle": "2025-08-27T19:51:05.705253Z",
     "shell.execute_reply": "2025-08-27T19:51:05.705077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              city   min   max  count     mean  median\n",
      "0            AFTON  1756  2015    495  1970.54  1981.0\n",
      "1    BARBOURSVILLE  1800  2016    405  1983.60  1988.0\n",
      "2  CHARLOTTESVILLE  1668  2016  21006  1985.40  1988.0\n",
      "3           CROZET  1700  2016   2978  1984.99  1999.0\n",
      "4      EARLYSVILLE  1735  2016   1909  1982.39  1985.0\n",
      "5           ESMONT  1740  2016    478  1966.10  1980.0\n",
      "6          KESWICK  1724  2016   1574  1986.63  1995.0\n",
      "7     NORTH GARDEN  1700  2016    603  1968.20  1980.0\n",
      "8            OTHER  1730  2016   1811  1972.30  1978.0\n",
      "9      SCOTTSVILLE  1732  2016   1040  1971.34  1979.0\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Group by operations\n",
    "# This function groups cases by common values of one or more columns\n",
    "\n",
    "# First, filter houses with yearbuilt info\n",
    "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0]\n",
    "\n",
    "# Group by city and compute summary statistics\n",
    "df_homes_stats = (\n",
    "    df_homes_filtered\n",
    "    .groupby(\"city\")[\"yearbuilt\"]\n",
    "    .agg([\"min\", \"max\", \"count\", \"mean\", \"median\"])\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(df_homes_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.706178Z",
     "iopub.status.busy": "2025-08-27T19:51:05.706121Z",
     "iopub.status.idle": "2025-08-27T19:51:05.714678Z",
     "shell.execute_reply": "2025-08-27T19:51:05.714450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yearbuilt condition  finsqft    city  median_yearbuilt  new\n",
      "0       2006   Average     1922  CROZET            1999.0    1\n",
      "1       2003   Average     1848  CROZET            1999.0    1\n",
      "2       1974   Average     1368   OTHER            1978.0    0\n",
      "3       1954   Average     1092   OTHER            1978.0    0\n",
      "4       1987   Average     1344   OTHER            1978.0    1\n"
     ]
    }
   ],
   "source": [
    "# If you don't want to obtain summaries but only within-group quantities\n",
    "# First, filter houses with yearbuilt info\n",
    "df_homes_filtered = df_homes[df_homes[\"yearbuilt\"] > 0].copy()\n",
    "\n",
    "# Calculate median year built by city\n",
    "median_by_city = df_homes_filtered.groupby(\"city\")[\"yearbuilt\"].median()\n",
    "\n",
    "# Add the median back to our dataframe\n",
    "df_homes_filtered[\"median_yearbuilt\"] = df_homes_filtered[\"city\"].map(median_by_city)\n",
    "\n",
    "# Create a new column indicating if house is newer than city median\n",
    "df_homes_filtered[\"new\"] = (df_homes_filtered[\"yearbuilt\"] >= df_homes_filtered[\"median_yearbuilt\"]).astype(int)\n",
    "\n",
    "# Select only the columns we want\n",
    "df_homes_stats = df_homes_filtered[[\"yearbuilt\", \"condition\", \"finsqft\", \"city\", \"median_yearbuilt\", \"new\"]]\n",
    "\n",
    "print(df_homes_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:51:05.715914Z",
     "iopub.status.busy": "2025-08-27T19:51:05.715824Z",
     "iopub.status.idle": "2025-08-27T19:51:05.721906Z",
     "shell.execute_reply": "2025-08-27T19:51:05.721719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               city  new   min   max  count     mean  median\n",
      "0             AFTON    0  1756  1980    243  1943.60  1960.0\n",
      "1             AFTON    1  1981  2015    252  1996.52  1996.0\n",
      "2     BARBOURSVILLE    0  1800  1987    192  1965.51  1973.0\n",
      "3     BARBOURSVILLE    1  1988  2016    213  1999.91  2001.0\n",
      "4   CHARLOTTESVILLE    0  1668  1987  10426  1970.46  1974.0\n",
      "5   CHARLOTTESVILLE    1  1988  2016  10580  2000.13  2000.0\n",
      "6            CROZET    0  1700  1998   1484  1962.37  1970.0\n",
      "7            CROZET    1  1999  2016   1494  2007.47  2006.0\n",
      "8       EARLYSVILLE    0  1735  1984    928  1966.63  1975.0\n",
      "9       EARLYSVILLE    1  1985  2016    981  1997.29  1997.0\n",
      "10           ESMONT    0  1740  1979    237  1933.14  1953.0\n",
      "11           ESMONT    1  1980  2016    241  1998.51  1999.0\n",
      "12          KESWICK    0  1724  1994    729  1968.40  1977.0\n",
      "13          KESWICK    1  1995  2016    845  2002.36  2001.0\n",
      "14     NORTH GARDEN    0  1700  1979    298  1939.06  1950.0\n",
      "15     NORTH GARDEN    1  1980  2016    305  1996.66  1997.0\n",
      "16            OTHER    0  1730  1977    879  1947.10  1963.0\n",
      "17            OTHER    1  1978  2016    932  1996.07  1996.0\n",
      "18      SCOTTSVILLE    0  1732  1978    507  1945.39  1962.0\n",
      "19      SCOTTSVILLE    1  1979  2016    533  1996.03  1995.0\n"
     ]
    }
   ],
   "source": [
    "# You can group by more than one variable\n",
    "# Group by both city and the \"new\" indicator we just created\n",
    "df_homes_stats = (\n",
    "    df_homes_filtered\n",
    "    .groupby([\"city\", \"new\"])[\"yearbuilt\"]\n",
    "    .agg([\"min\", \"max\", \"count\", \"mean\", \"median\"])\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(df_homes_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ FIN!!\n",
    "\n",
    "### Recap:\n",
    "We covered the most useful analysis data structure in Python -- the DataFrame. We'll use that structure a lot in the next few weeks.\n",
    "\n",
    "### Next week:\n",
    "We will learn how we can visualize data using Python\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
